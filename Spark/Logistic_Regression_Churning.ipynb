{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression-Churning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task: Create a machine learning model that will help predict which customers will churn  so that they can correctly assign the customers most at risk to churn an account manager. Then test out the model on some new data that has been provided (new_customers.csv). Which customers are most likely to churn given this unlabeled data?\n",
    "\n",
    "## Results: Accuracy of the logistic regression model on the test data is high at .91.  Of the six customers/companies in the new customers data set,  Cannon-Benson,  Barron-Robertson, Sexton-Golden, and Parks-Robbins are likely to churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('churn').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spark to read in the Cruise Ship Info csv file.\n",
    "data = spark.read.csv(\"spark_master/Spark_for_Machine_Learning/Logistic_Regression/customer_churn.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the Schema of the DataFrame\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date=datetime.datetime(2013, 8, 30, 7, 0, 40), Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Kevin Mueller', Age=41.0, Total_Purchase=11916.22, Account_Manager=0, Years=6.5, Num_Sites=11.0, Onboard_date=datetime.datetime(2013, 8, 13, 0, 38, 46), Location='6157 Frank Gardens Suite 019 Carloshaven, RI 17756', Company='Wilson PLC', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Eric Lozano', Age=38.0, Total_Purchase=12884.75, Account_Manager=0, Years=6.67, Num_Sites=12.0, Onboard_date=datetime.datetime(2016, 6, 29, 6, 20, 7), Location='1331 Keith Court Alyssahaven, DE 90114', Company='Miller, Johnson and Wallace', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Phillip White', Age=42.0, Total_Purchase=8010.76, Account_Manager=0, Years=6.71, Num_Sites=10.0, Onboard_date=datetime.datetime(2014, 4, 22, 12, 43, 12), Location='13120 Daniel Mount Angelabury, WY 30645-4695', Company='Smith Inc', Churn=1)\n",
      "\n",
      "\n",
      "Row(Names='Cynthia Norton', Age=37.0, Total_Purchase=9191.58, Account_Manager=0, Years=5.56, Num_Sites=9.0, Onboard_date=datetime.datetime(2016, 1, 19, 15, 31, 15), Location='765 Tricia Row Karenshire, MH 71730', Company='Love-Jones', Churn=1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in data.head(5):\n",
    "    print(item)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few things we need to do before Spark can accept the data!\n",
    "# It needs to be in the form of two columns\n",
    "# (\"label\",\"features\")\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List the column names in the data set\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Location|count|\n",
      "+--------------------+-----+\n",
      "|062 Trevor Falls ...|    1|\n",
      "|066 Jenkins Walks...|    1|\n",
      "|45946 Day Springs...|    1|\n",
      "|143 Andrea Flat L...|    1|\n",
      "|Unit 2093 Box 153...|    1|\n",
      "|399 Herbert Key P...|    1|\n",
      "|104 Ruben Rapid A...|    1|\n",
      "|930 Carrie Harbor...|    1|\n",
      "|8202 Jade Unions ...|    1|\n",
      "|USCGC Bailey FPO ...|    1|\n",
      "|893 Carla Trace S...|    1|\n",
      "|446 Rodney Ridge ...|    1|\n",
      "|30668 Isabella Fr...|    1|\n",
      "|911 Kent Point An...|    1|\n",
      "|078 Nunez Haven S...|    1|\n",
      "|PSC 5667, Box 831...|    1|\n",
      "|4972 Michael Vill...|    1|\n",
      "|567 Ian Loop Lamb...|    1|\n",
      "|482 Wells Mountai...|    1|\n",
      "|7259 Brown Street...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Examine Location variable. Since it is not factorable, it will not be used to train the model.\n",
    "count = data.groupBy('Location').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Company|count|\n",
      "+--------------------+-----+\n",
      "|Miller, Johnson a...|    1|\n",
      "|Hunter, Reyes and...|    1|\n",
      "|          Obrien PLC|    1|\n",
      "|            Soto PLC|    2|\n",
      "|            Todd LLC|    1|\n",
      "|Smith, Marshall a...|    1|\n",
      "|           Smith PLC|    1|\n",
      "|          Hall Group|    1|\n",
      "|Freeman, Lam and ...|    1|\n",
      "|       Smith-Carroll|    1|\n",
      "|Hall, Hernandez a...|    1|\n",
      "|          Cannon Inc|    1|\n",
      "|        White-Dennis|    1|\n",
      "|Wilson, Collins a...|    1|\n",
      "|Jennings, Gates a...|    1|\n",
      "|     Campbell-Willis|    1|\n",
      "|    Martinez-Roberts|    1|\n",
      "|        Robinson PLC|    1|\n",
      "|          Barton Inc|    1|\n",
      "|Hernandez, Middle...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Examine Company variable. Since it is not factorable, it will not be used to train the model.\n",
    "count = data.groupBy('Company').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following attributes were omitted: 'Names','Account_Manager' (these were assigned randomly), 'Onboard_date', \n",
    "#'Location','Company'\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Age', 'Total_Purchase', 'Years', 'Num_Sites'],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the assembler to transform the data into two columns: features, Churn\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|Churn|\n",
      "+--------------------+-----+\n",
      "|[42.0,11066.8,7.2...|    1|\n",
      "|[41.0,11916.22,6....|    1|\n",
      "|[38.0,12884.75,6....|    1|\n",
      "|[42.0,8010.76,6.7...|    1|\n",
      "|[37.0,9191.58,5.5...|    1|\n",
      "|[48.0,10356.02,5....|    1|\n",
      "|[44.0,11331.58,5....|    1|\n",
      "|[32.0,9885.12,6.9...|    1|\n",
      "|[43.0,14062.6,5.4...|    1|\n",
      "|[40.0,8066.94,7.1...|    1|\n",
      "|[30.0,11575.37,5....|    1|\n",
      "|[45.0,8771.02,6.6...|    1|\n",
      "|[45.0,8988.67,4.8...|    1|\n",
      "|[40.0,8283.32,5.1...|    1|\n",
      "|[41.0,6569.87,4.3...|    1|\n",
      "|[38.0,10494.82,6....|    1|\n",
      "|[45.0,8213.41,7.3...|    1|\n",
      "|[43.0,11226.88,8....|    1|\n",
      "|[53.0,5515.09,6.8...|    1|\n",
      "|[46.0,8046.4,5.69...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the output dataframe\n",
    "output.select(\"features\",\"Churn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach the dataframe to an object\n",
    "final_data = output.select(\"features\",'Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train & test: 70% train, 30% test\n",
    "train_churn,test_churn = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                626|\n",
      "|   mean|0.17412140575079874|\n",
      "| stddev| 0.3795170968969129|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View train data\n",
    "train_churn.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                274|\n",
      "|   mean|0.14963503649635038|\n",
      "| stddev| 0.3573660434685389|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View test data\n",
    "test_churn.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model object\n",
    "churn_lr = LogisticRegression(labelCol='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and call this model churn_lrModel\n",
    "churn_lrModel = churn_lr.fit(train_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object with summary model data \n",
    "training_sum = churn_lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              Churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                626|                626|\n",
      "|   mean|0.17412140575079874|0.12300319488817892|\n",
      "| stddev| 0.3795170968969129|0.32870352354329324|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the object\n",
    "training_sum.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the model, churn_lrModel to the test data\n",
    "pred_and_labels = churn_lrModel.evaluate(test_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[22.0,11254.38,4....|    0|[4.29340632296435...|[0.98652571480195...|       0.0|\n",
      "|[28.0,8670.98,3.9...|    0|[7.14143718163282...|[0.99920901257036...|       0.0|\n",
      "|[28.0,11204.23,3....|    0|[1.09075590062981...|[0.74852403589785...|       0.0|\n",
      "|[28.0,11245.38,6....|    0|[3.22120108594342...|[0.96162436269381...|       0.0|\n",
      "|[29.0,10203.18,5....|    0|[3.70803782670405...|[0.97606150634386...|       0.0|\n",
      "|[30.0,10960.52,5....|    0|[2.33571362166432...|[0.91179195090912...|       0.0|\n",
      "|[30.0,13473.35,3....|    0|[1.88886504197959...|[0.86862606920732...|       0.0|\n",
      "|[31.0,8829.83,4.5...|    0|[4.37510481124901...|[0.98756963585975...|       0.0|\n",
      "|[31.0,9574.89,7.3...|    0|[2.97533524147837...|[0.95144733457579...|       0.0|\n",
      "|[32.0,6367.22,2.8...|    0|[2.99350190144158...|[0.95227969959841...|       0.0|\n",
      "|[32.0,7896.65,7.1...|    0|[3.20694953959675...|[0.96109496474820...|       0.0|\n",
      "|[32.0,8011.38,5.3...|    0|[1.64861657801798...|[0.83870398932167...|       0.0|\n",
      "|[32.0,11540.86,3....|    0|[5.96350463405683...|[0.99743570635700...|       0.0|\n",
      "|[32.0,12479.72,4....|    0|[3.89527480581031...|[0.98006759619812...|       0.0|\n",
      "|[32.0,13630.93,4....|    0|[1.53717936920442...|[0.82305431433367...|       0.0|\n",
      "|[33.0,7720.61,4.9...|    0|[1.81537792216339...|[0.86001058950991...|       0.0|\n",
      "|[33.0,10306.21,6....|    0|[2.09064365951363...|[0.88999046051407...|       0.0|\n",
      "|[33.0,10709.39,5....|    0|[6.15264922877944...|[0.99787668090833...|       0.0|\n",
      "|[33.0,12638.51,5....|    0|[3.67847950861351...|[0.97536105775247...|       0.0|\n",
      "|[33.0,13314.19,5....|    0|[2.21455206525098...|[0.90154870112378...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the results from applying the model to the test data\n",
    "pred_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate using ACC churn_lrModel using test data\n",
    "acc = evaluator.evaluate(pred_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9051094890510949"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out accurancy\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to all of the data and call this model final_lrModel\n",
    "final_lr_model = churn_lr.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spark to read in the new_customers csv file.\n",
    "new_customers = spark.read.csv(\"spark_master/Spark_for_Machine_Learning/Logistic_Regression/new_customers.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print schema\n",
    "new_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use assembler to transform new_customer data set\n",
    "test_new_customers = assembler.transform(new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print schema\n",
    "test_new_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+-----------------+------------------+-----------------+------------------+--------------------+----------------+\n",
      "|summary|        Names|               Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|         Company|\n",
      "+-------+-------------+------------------+-----------------+------------------+-----------------+------------------+--------------------+----------------+\n",
      "|  count|            6|                 6|                6|                 6|                6|                 6|                   6|               6|\n",
      "|   mean|         null|35.166666666666664|7607.156666666667|0.8333333333333334|6.808333333333334|12.333333333333334|                null|            null|\n",
      "| stddev|         null| 15.71517313511584|4346.008232825459| 0.408248290463863|3.708737880555414|3.3862466931200785|                null|            null|\n",
      "|    min|Andrew Mccall|              22.0|            100.0|                 0|              1.0|               8.0|085 Austin Views ...|Barron-Robertson|\n",
      "|    max| Taylor Young|              65.0|         13147.71|                 1|             10.0|              15.0|Unit 0789 Box 073...|        Wood LLC|\n",
      "+-------+-------------+------------------+-----------------+------------------+-----------------+------------------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the test_new_customers info; Only 6 customers\n",
    "test_new_customers.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply model to the transformed new_customers data set\n",
    "final_results = final_lr_model.transform(test_new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|         Company|prediction|\n",
      "+----------------+----------+\n",
      "|        King Ltd|       0.0|\n",
      "|   Cannon-Benson|       1.0|\n",
      "|Barron-Robertson|       1.0|\n",
      "|   Sexton-Golden|       1.0|\n",
      "|        Wood LLC|       0.0|\n",
      "|   Parks-Robbins|       1.0|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.select('Company','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: Accuracy of the logistic regression model on the test data is high at .91.  Of the six customers/companies in the new customers data set,  Cannon-Benson,  Barron-Robertson, Sexton-Golden, and Parks-Robbins are likely to churn."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
